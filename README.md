# Azure End-to-End Data Engineering Project ðŸš€

This project demonstrates an end-to-end Azure data pipeline using various Azure services. It covers data ingestion, transformation, storage, and visualization.

---

## ðŸ§  Tech Stack

- **Azure Data Factory**
- **Azure Blob Storage**
- **Azure SQL Database**
- **Azure Databricks (PySpark)**
- **Azure Synapse Analytics**
- **Power BI**
- **Azure Key Vault**



---

## ðŸ”„ Data Flow

1. Raw data ingested into Azure Blob Storage
2. ADF copies raw data to a staging zone
3. Databricks cleans and transforms the data
4. Clean data stored in Azure SQL DB or Synapse
5. Power BI connects to SQL/Synapse for reporting

---

l        

---

## ðŸ“¦ Setup Instructions

1. Clone this repo  
   ```bash
   git clone https://github.com/sriPravallika0110/azure-end-to-end-data-pipeline.git
   ```

2. Upload data to Azure Blob Storage

3. Import ADF pipeline JSON

4. Upload notebooks to Databricks

5. Run the pipeline and validate data

---

## ðŸ“ˆ Output Example

- âœ… Transformed CSV files
- âœ… Processed tables in Synapse
- âœ… Interactive Power BI reports

---
